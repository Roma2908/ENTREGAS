{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed310dce-f3f6-49f2-b4ab-5dabe5ded5b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "I5g8tGQu03OV"
   },
   "source": [
    "### CREAMOS EL ARCHIVO SQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30e2c1df-f4a1-4789-a30d-88adc44eb47f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ybg247eL06fc"
   },
   "outputs": [],
   "source": [
    "with open(\"consulta.sql\", \"w\") as file:\n",
    "    file.write(\"SELECT * FROM Ejemplo;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10788aba-e350-4f7a-a252-e47047e4a7fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#PROBAMOS QUE FUNCIONA BIEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ca9f5a8-5bb6-4813-a3bf-7138acf36654",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo guardado en: /Workspace/Users/azzure_roma_29@hotmail.com/ENTREGAS/Carpeta_ejemplo/mi_parquet.parquet\nDataFrame desde .parquet:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Dinero</th><th>Valor1</th><th>Valor2</th><th>Valo3</th><th>Valor4</th></tr></thead><tbody><tr><td>5</td><td>3</td><td>7</td><td>1</td><td>9</td></tr><tr><td>2</td><td>6</td><td>8</td><td>4</td><td>3</td></tr><tr><td>10</td><td>1</td><td>5</td><td>7</td><td>2</td></tr><tr><td>6</td><td>9</td><td>3</td><td>8</td><td>1</td></tr><tr><td>4</td><td>7</td><td>2</td><td>6</td><td>10</td></tr><tr><td>9</td><td>3</td><td>4</td><td>2</td><td>7</td></tr><tr><td>7</td><td>2</td><td>10</td><td>3</td><td>6</td></tr><tr><td>1</td><td>8</td><td>9</td><td>5</td><td>4</td></tr><tr><td>3</td><td>5</td><td>6</td><td>10</td><td>8</td></tr><tr><td>8</td><td>4</td><td>1</td><td>9</td><td>5</td></tr><tr><td>2</td><td>7</td><td>8</td><td>3</td><td>6</td></tr><tr><td>6</td><td>1</td><td>2</td><td>5</td><td>10</td></tr><tr><td>10</td><td>3</td><td>4</td><td>7</td><td>9</td></tr><tr><td>5</td><td>9</td><td>6</td><td>1</td><td>2</td></tr><tr><td>7</td><td>6</td><td>1</td><td>8</td><td>3</td></tr><tr><td>3</td><td>2</td><td>5</td><td>10</td><td>7</td></tr><tr><td>9</td><td>1</td><td>3</td><td>4</td><td>6</td></tr><tr><td>4</td><td>8</td><td>7</td><td>2</td><td>10</td></tr><tr><td>1</td><td>5</td><td>9</td><td>6</td><td>3</td></tr><tr><td>6</td><td>7</td><td>10</td><td>5</td><td>2</td></tr><tr><td>8</td><td>3</td><td>1</td><td>9</td><td>4</td></tr><tr><td>2</td><td>10</td><td>6</td><td>7</td><td>1</td></tr><tr><td>5</td><td>4</td><td>8</td><td>2</td><td>9</td></tr><tr><td>7</td><td>9</td><td>3</td><td>6</td><td>10</td></tr><tr><td>1</td><td>2</td><td>5</td><td>8</td><td>7</td></tr><tr><td>6</td><td>5</td><td>4</td><td>3</td><td>2</td></tr><tr><td>10</td><td>8</td><td>7</td><td>1</td><td>9</td></tr><tr><td>3</td><td>6</td><td>9</td><td>4</td><td>5</td></tr><tr><td>4</td><td>1</td><td>2</td><td>10</td><td>6</td></tr><tr><td>9</td><td>7</td><td>8</td><td>5</td><td>3</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         5,
         3,
         7,
         1,
         9
        ],
        [
         2,
         6,
         8,
         4,
         3
        ],
        [
         10,
         1,
         5,
         7,
         2
        ],
        [
         6,
         9,
         3,
         8,
         1
        ],
        [
         4,
         7,
         2,
         6,
         10
        ],
        [
         9,
         3,
         4,
         2,
         7
        ],
        [
         7,
         2,
         10,
         3,
         6
        ],
        [
         1,
         8,
         9,
         5,
         4
        ],
        [
         3,
         5,
         6,
         10,
         8
        ],
        [
         8,
         4,
         1,
         9,
         5
        ],
        [
         2,
         7,
         8,
         3,
         6
        ],
        [
         6,
         1,
         2,
         5,
         10
        ],
        [
         10,
         3,
         4,
         7,
         9
        ],
        [
         5,
         9,
         6,
         1,
         2
        ],
        [
         7,
         6,
         1,
         8,
         3
        ],
        [
         3,
         2,
         5,
         10,
         7
        ],
        [
         9,
         1,
         3,
         4,
         6
        ],
        [
         4,
         8,
         7,
         2,
         10
        ],
        [
         1,
         5,
         9,
         6,
         3
        ],
        [
         6,
         7,
         10,
         5,
         2
        ],
        [
         8,
         3,
         1,
         9,
         4
        ],
        [
         2,
         10,
         6,
         7,
         1
        ],
        [
         5,
         4,
         8,
         2,
         9
        ],
        [
         7,
         9,
         3,
         6,
         10
        ],
        [
         1,
         2,
         5,
         8,
         7
        ],
        [
         6,
         5,
         4,
         3,
         2
        ],
        [
         10,
         8,
         7,
         1,
         9
        ],
        [
         3,
         6,
         9,
         4,
         5
        ],
        [
         4,
         1,
         2,
         10,
         6
        ],
        [
         9,
         7,
         8,
         5,
         3
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Dinero",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Valor1",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Valor2",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Valo3",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Valor4",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from Lector_deConsulta import ConsultaDB\n",
    "\n",
    "# 1) Instanciar y ejecutar consulta\n",
    "lector = ConsultaDB()            # lee config.json y prepara conexión\n",
    "df = lector.ejecutar_consulta()  # ejecuta consulta.sql\n",
    "\n",
    "# 2) Exportar a Parquet\n",
    "lector.exportar(df, nombre_archivo=\"mi_parquet\", formato=\"parquet\")\n",
    "\n",
    "# 3) Leer el Parquet recién generado\n",
    "ruta_parquet = os.path.join(lector.output_dir, \"mi_parquet.parquet\")\n",
    "df_parquet = pd.read_parquet(ruta_parquet)\n",
    "\n",
    "# 4) Imprimir y mostrar\n",
    "print(\"DataFrame desde .parquet:\")\n",
    "display(df_parquet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e74b1e74-a2e9-4aad-9167-3eae83aa7efd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## FUNCIONA PERO TOCA CAMBIAR EL DF POR UNO DE MAYOR TAMAÑO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1778aff9-f9cf-4788-913c-ca57c0d4b629",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qACZOyfB3bLi",
    "outputId": "308753c2-fd04-41c8-9912-377bb829ce73"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n[LightGBM] [Info] Total Bins 0\n[LightGBM] [Info] Number of data points in the train set: 24, number of used features: 0\n[LightGBM] [Info] Start training from score 5.625000\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2712e4e1392342cf9c27b8acd6ebdee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>variable</th><th>importancia</th></tr></thead><tbody><tr><td>Valor1</td><td>0.0</td></tr><tr><td>Valor2</td><td>0.0</td></tr><tr><td>Valo3</td><td>0.0</td></tr><tr><td>Valor4</td><td>0.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Valor1",
         0.0
        ],
        [
         "Valor2",
         0.0
        ],
        [
         "Valo3",
         0.0
        ],
        [
         "Valor4",
         0.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "variable",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "importancia",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables seleccionadas (0): []\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-5255411454592102>, line 79\u001B[0m\n",
       "\u001B[1;32m     69\u001B[0m \u001B[38;5;66;03m# 10. Modelo final con variables seleccionadas\u001B[39;00m\n",
       "\u001B[1;32m     70\u001B[0m pipeline_final \u001B[38;5;241m=\u001B[39m Pipeline(steps\u001B[38;5;241m=\u001B[39m[\n",
       "\u001B[1;32m     71\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprep\u001B[39m\u001B[38;5;124m\"\u001B[39m, ColumnTransformer(\n",
       "\u001B[1;32m     72\u001B[0m         transformers\u001B[38;5;241m=\u001B[39m[\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m     76\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m, LGBMRegressor(n_estimators\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m300\u001B[39m, learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.03\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)),\n",
       "\u001B[1;32m     77\u001B[0m ])\n",
       "\u001B[0;32m---> 79\u001B[0m pipeline_final\u001B[38;5;241m.\u001B[39mfit(X_train_red, y_train)\n",
       "\u001B[1;32m     80\u001B[0m predicciones \u001B[38;5;241m=\u001B[39m pipeline_final\u001B[38;5;241m.\u001B[39mpredict(X_test_red)\n",
       "\u001B[1;32m     82\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mR² en prueba:\u001B[39m\u001B[38;5;124m\"\u001B[39m, r2_score(y_test, predicciones)\u001B[38;5;241m.\u001B[39mround(\u001B[38;5;241m4\u001B[39m))\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:578\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    576\u001B[0m     patch_function\u001B[38;5;241m.\u001B[39mcall(call_original, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m    577\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m--> 578\u001B[0m     patch_function(call_original, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m    580\u001B[0m session\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msucceeded\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    582\u001B[0m try_log_autologging_event(\n",
       "\u001B[1;32m    583\u001B[0m     AutologgingEventLogger\u001B[38;5;241m.\u001B[39mget_logger()\u001B[38;5;241m.\u001B[39mlog_patch_function_success,\n",
       "\u001B[1;32m    584\u001B[0m     session,\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    588\u001B[0m     kwargs,\n",
       "\u001B[1;32m    589\u001B[0m )\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:251\u001B[0m, in \u001B[0;36mwith_managed_run.<locals>.patch_with_managed_run\u001B[0;34m(original, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    248\u001B[0m     managed_run \u001B[38;5;241m=\u001B[39m create_managed_run()\n",
       "\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m--> 251\u001B[0m     result \u001B[38;5;241m=\u001B[39m patch_function(original, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mException\u001B[39;00m, \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m):\n",
       "\u001B[1;32m    253\u001B[0m     \u001B[38;5;66;03m# In addition to standard Python exceptions, handle keyboard interrupts to ensure\u001B[39;00m\n",
       "\u001B[1;32m    254\u001B[0m     \u001B[38;5;66;03m# that runs are terminated if a user prematurely interrupts training execution\u001B[39;00m\n",
       "\u001B[1;32m    255\u001B[0m     \u001B[38;5;66;03m# (e.g. via sigint / ctrl-c)\u001B[39;00m\n",
       "\u001B[1;32m    256\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m managed_run:\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/mlflow/sklearn/__init__.py:1652\u001B[0m, in \u001B[0;36m_autolog.<locals>.patched_fit\u001B[0;34m(fit_impl, allow_children_patch, original, self, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   1648\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mshould_log():\n",
       "\u001B[1;32m   1649\u001B[0m     \u001B[38;5;66;03m# In `fit_mlflow` call, it will also call metric API for computing training metrics\u001B[39;00m\n",
       "\u001B[1;32m   1650\u001B[0m     \u001B[38;5;66;03m# so we need temporarily disable the post_training_metrics patching.\u001B[39;00m\n",
       "\u001B[1;32m   1651\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m _AUTOLOGGING_METRICS_MANAGER\u001B[38;5;241m.\u001B[39mdisable_log_post_training_metrics():\n",
       "\u001B[0;32m-> 1652\u001B[0m         result \u001B[38;5;241m=\u001B[39m fit_impl(original, \u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m   1653\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m should_log_post_training_metrics:\n",
       "\u001B[1;32m   1654\u001B[0m         _AUTOLOGGING_METRICS_MANAGER\u001B[38;5;241m.\u001B[39mregister_model(\n",
       "\u001B[1;32m   1655\u001B[0m             \u001B[38;5;28mself\u001B[39m, mlflow\u001B[38;5;241m.\u001B[39mactive_run()\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mrun_id\n",
       "\u001B[1;32m   1656\u001B[0m         )\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/mlflow/sklearn/__init__.py:1427\u001B[0m, in \u001B[0;36m_autolog.<locals>.fit_mlflow\u001B[0;34m(original, self, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   1425\u001B[0m _log_pretraining_metadata(autologging_client, \u001B[38;5;28mself\u001B[39m, X, y_true)\n",
       "\u001B[1;32m   1426\u001B[0m params_logging_future \u001B[38;5;241m=\u001B[39m autologging_client\u001B[38;5;241m.\u001B[39mflush(synchronous\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
       "\u001B[0;32m-> 1427\u001B[0m fit_output \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m   1428\u001B[0m _log_posttraining_metadata(autologging_client, \u001B[38;5;28mself\u001B[39m, X, y_true, sample_weight)\n",
       "\u001B[1;32m   1429\u001B[0m autologging_client\u001B[38;5;241m.\u001B[39mflush(synchronous\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:559\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001B[0;34m(*og_args, **og_kwargs)\u001B[0m\n",
       "\u001B[1;32m    556\u001B[0m         original_result \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;241m*\u001B[39m_og_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_og_kwargs)\n",
       "\u001B[1;32m    557\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n",
       "\u001B[0;32m--> 559\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:494\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001B[0;34m(original_fn, og_args, og_kwargs)\u001B[0m\n",
       "\u001B[1;32m    485\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[1;32m    486\u001B[0m     try_log_autologging_event(\n",
       "\u001B[1;32m    487\u001B[0m         AutologgingEventLogger\u001B[38;5;241m.\u001B[39mget_logger()\u001B[38;5;241m.\u001B[39mlog_original_function_start,\n",
       "\u001B[1;32m    488\u001B[0m         session,\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    492\u001B[0m         og_kwargs,\n",
       "\u001B[1;32m    493\u001B[0m     )\n",
       "\u001B[0;32m--> 494\u001B[0m     original_fn_result \u001B[38;5;241m=\u001B[39m original_fn(\u001B[38;5;241m*\u001B[39mog_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mog_kwargs)\n",
       "\u001B[1;32m    496\u001B[0m     try_log_autologging_event(\n",
       "\u001B[1;32m    497\u001B[0m         AutologgingEventLogger\u001B[38;5;241m.\u001B[39mget_logger()\u001B[38;5;241m.\u001B[39mlog_original_function_success,\n",
       "\u001B[1;32m    498\u001B[0m         session,\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    502\u001B[0m         og_kwargs,\n",
       "\u001B[1;32m    503\u001B[0m     )\n",
       "\u001B[1;32m    504\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_fn_result\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:556\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001B[0;34m(*_og_args, **_og_kwargs)\u001B[0m\n",
       "\u001B[1;32m    548\u001B[0m \u001B[38;5;66;03m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001B[39;00m\n",
       "\u001B[1;32m    549\u001B[0m \u001B[38;5;66;03m# during original function execution, even if silent mode is enabled\u001B[39;00m\n",
       "\u001B[1;32m    550\u001B[0m \u001B[38;5;66;03m# (`silent=True`), since these warnings originate from the ML framework\u001B[39;00m\n",
       "\u001B[1;32m    551\u001B[0m \u001B[38;5;66;03m# or one of its dependencies and are likely relevant to the caller\u001B[39;00m\n",
       "\u001B[1;32m    552\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n",
       "\u001B[1;32m    553\u001B[0m     disable_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n",
       "\u001B[1;32m    554\u001B[0m     reroute_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n",
       "\u001B[1;32m    555\u001B[0m ):\n",
       "\u001B[0;32m--> 556\u001B[0m     original_result \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;241m*\u001B[39m_og_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_og_kwargs)\n",
       "\u001B[1;32m    557\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/MLWorkloadsInstrumentation/_sklearn.py:29\u001B[0m, in \u001B[0;36m_create_patch_function.<locals>.patch_function\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[1;32m     28\u001B[0m     original_succeeded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
       "\u001B[0;32m---> 29\u001B[0m     original_result \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m     30\u001B[0m     original_succeeded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
       "\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/base.py:1151\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   1144\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n",
       "\u001B[1;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n",
       "\u001B[1;32m   1147\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n",
       "\u001B[1;32m   1148\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n",
       "\u001B[1;32m   1149\u001B[0m     )\n",
       "\u001B[1;32m   1150\u001B[0m ):\n",
       "\u001B[0;32m-> 1151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/pipeline.py:420\u001B[0m, in \u001B[0;36mPipeline.fit\u001B[0;34m(self, X, y, **fit_params)\u001B[0m\n",
       "\u001B[1;32m    418\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_final_estimator \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpassthrough\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
       "\u001B[1;32m    419\u001B[0m         fit_params_last_step \u001B[38;5;241m=\u001B[39m fit_params_steps[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m][\u001B[38;5;241m0\u001B[39m]]\n",
       "\u001B[0;32m--> 420\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_final_estimator\u001B[38;5;241m.\u001B[39mfit(Xt, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params_last_step)\n",
       "\u001B[1;32m    422\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:458\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n",
       "\u001B[1;32m    444\u001B[0m     active_session_failed\n",
       "\u001B[1;32m    445\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m autologging_is_disabled(autologging_integration)\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    452\u001B[0m     \u001B[38;5;66;03m# warning behavior during original function execution, since autologging is being\u001B[39;00m\n",
       "\u001B[1;32m    453\u001B[0m     \u001B[38;5;66;03m# skipped\u001B[39;00m\n",
       "\u001B[1;32m    454\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n",
       "\u001B[1;32m    455\u001B[0m         disable_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n",
       "\u001B[1;32m    456\u001B[0m         reroute_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n",
       "\u001B[1;32m    457\u001B[0m     ):\n",
       "\u001B[0;32m--> 458\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m original(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m    460\u001B[0m \u001B[38;5;66;03m# Whether or not the original / underlying function has been called during the\u001B[39;00m\n",
       "\u001B[1;32m    461\u001B[0m \u001B[38;5;66;03m# execution of patched code\u001B[39;00m\n",
       "\u001B[1;32m    462\u001B[0m original_has_been_called \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-049cd929-ff6b-45f7-85dc-aeefbfc6f73e/lib/python3.11/site-packages/lightgbm/sklearn.py:1398\u001B[0m, in \u001B[0;36mLGBMRegressor.fit\u001B[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001B[0m\n",
       "\u001B[1;32m   1381\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(  \u001B[38;5;66;03m# type: ignore[override]\u001B[39;00m\n",
       "\u001B[1;32m   1382\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n",
       "\u001B[1;32m   1383\u001B[0m     X: _LGBM_ScikitMatrixLike,\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m   1395\u001B[0m     init_model: Optional[Union[\u001B[38;5;28mstr\u001B[39m, Path, Booster, LGBMModel]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n",
       "\u001B[1;32m   1396\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLGBMRegressor\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
       "\u001B[1;32m   1397\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001B[39;00m\n",
       "\u001B[0;32m-> 1398\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mfit(\n",
       "\u001B[1;32m   1399\u001B[0m         X,\n",
       "\u001B[1;32m   1400\u001B[0m         y,\n",
       "\u001B[1;32m   1401\u001B[0m         sample_weight\u001B[38;5;241m=\u001B[39msample_weight,\n",
       "\u001B[1;32m   1402\u001B[0m         init_score\u001B[38;5;241m=\u001B[39minit_score,\n",
       "\u001B[1;32m   1403\u001B[0m         eval_set\u001B[38;5;241m=\u001B[39meval_set,\n",
       "\u001B[1;32m   1404\u001B[0m         eval_names\u001B[38;5;241m=\u001B[39meval_names,\n",
       "\u001B[1;32m   1405\u001B[0m         eval_sample_weight\u001B[38;5;241m=\u001B[39meval_sample_weight,\n",
       "\u001B[1;32m   1406\u001B[0m         eval_init_score\u001B[38;5;241m=\u001B[39meval_init_score,\n",
       "\u001B[1;32m   1407\u001B[0m         eval_metric\u001B[38;5;241m=\u001B[39meval_metric,\n",
       "\u001B[1;32m   1408\u001B[0m         feature_name\u001B[38;5;241m=\u001B[39mfeature_name,\n",
       "\u001B[1;32m   1409\u001B[0m         categorical_feature\u001B[38;5;241m=\u001B[39mcategorical_feature,\n",
       "\u001B[1;32m   1410\u001B[0m         callbacks\u001B[38;5;241m=\u001B[39mcallbacks,\n",
       "\u001B[1;32m   1411\u001B[0m         init_model\u001B[38;5;241m=\u001B[39minit_model,\n",
       "\u001B[1;32m   1412\u001B[0m     )\n",
       "\u001B[1;32m   1413\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:458\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n",
       "\u001B[1;32m    444\u001B[0m     active_session_failed\n",
       "\u001B[1;32m    445\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m autologging_is_disabled(autologging_integration)\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    452\u001B[0m     \u001B[38;5;66;03m# warning behavior during original function execution, since autologging is being\u001B[39;00m\n",
       "\u001B[1;32m    453\u001B[0m     \u001B[38;5;66;03m# skipped\u001B[39;00m\n",
       "\u001B[1;32m    454\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n",
       "\u001B[1;32m    455\u001B[0m         disable_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n",
       "\u001B[1;32m    456\u001B[0m         reroute_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n",
       "\u001B[1;32m    457\u001B[0m     ):\n",
       "\u001B[0;32m--> 458\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m original(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m    460\u001B[0m \u001B[38;5;66;03m# Whether or not the original / underlying function has been called during the\u001B[39;00m\n",
       "\u001B[1;32m    461\u001B[0m \u001B[38;5;66;03m# execution of patched code\u001B[39;00m\n",
       "\u001B[1;32m    462\u001B[0m original_has_been_called \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-049cd929-ff6b-45f7-85dc-aeefbfc6f73e/lib/python3.11/site-packages/lightgbm/sklearn.py:949\u001B[0m, in \u001B[0;36mLGBMModel.fit\u001B[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001B[0m\n",
       "\u001B[1;32m    946\u001B[0m params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetric\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m [metric \u001B[38;5;28;01mfor\u001B[39;00m metric \u001B[38;5;129;01min\u001B[39;00m params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetric\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m metric \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m]\n",
       "\u001B[1;32m    948\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(X, (pd_DataFrame, dt_DataTable)):\n",
       "\u001B[0;32m--> 949\u001B[0m     _X, _y \u001B[38;5;241m=\u001B[39m _LGBMValidateData(\n",
       "\u001B[1;32m    950\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n",
       "\u001B[1;32m    951\u001B[0m         X,\n",
       "\u001B[1;32m    952\u001B[0m         y,\n",
       "\u001B[1;32m    953\u001B[0m         reset\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n",
       "\u001B[1;32m    954\u001B[0m         \u001B[38;5;66;03m# allow any input type (this validation is done further down, in lgb.Dataset())\u001B[39;00m\n",
       "\u001B[1;32m    955\u001B[0m         accept_sparse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n",
       "\u001B[1;32m    956\u001B[0m         \u001B[38;5;66;03m# do not raise an error if Inf of NaN values are found (LightGBM handles these internally)\u001B[39;00m\n",
       "\u001B[1;32m    957\u001B[0m         ensure_all_finite\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n",
       "\u001B[1;32m    958\u001B[0m         \u001B[38;5;66;03m# raise an error on 0-row and 1-row inputs\u001B[39;00m\n",
       "\u001B[1;32m    959\u001B[0m         ensure_min_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n",
       "\u001B[1;32m    960\u001B[0m     )\n",
       "\u001B[1;32m    961\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[1;32m    962\u001B[0m         sample_weight \u001B[38;5;241m=\u001B[39m _LGBMCheckSampleWeight(sample_weight, _X)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-049cd929-ff6b-45f7-85dc-aeefbfc6f73e/lib/python3.11/site-packages/lightgbm/compat.py:78\u001B[0m, in \u001B[0;36mvalidate_data\u001B[0;34m(_estimator, X, y, accept_sparse, ensure_all_finite, ensure_min_samples, **ignored_kwargs)\u001B[0m\n",
       "\u001B[1;32m     71\u001B[0m     X \u001B[38;5;241m=\u001B[39m check_array(\n",
       "\u001B[1;32m     72\u001B[0m         X,\n",
       "\u001B[1;32m     73\u001B[0m         accept_sparse\u001B[38;5;241m=\u001B[39maccept_sparse,\n",
       "\u001B[1;32m     74\u001B[0m         force_all_finite\u001B[38;5;241m=\u001B[39mensure_all_finite,\n",
       "\u001B[1;32m     75\u001B[0m         ensure_min_samples\u001B[38;5;241m=\u001B[39mensure_min_samples,\n",
       "\u001B[1;32m     76\u001B[0m     )\n",
       "\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m---> 78\u001B[0m     X, y \u001B[38;5;241m=\u001B[39m check_X_y(\n",
       "\u001B[1;32m     79\u001B[0m         X,\n",
       "\u001B[1;32m     80\u001B[0m         y,\n",
       "\u001B[1;32m     81\u001B[0m         accept_sparse\u001B[38;5;241m=\u001B[39maccept_sparse,\n",
       "\u001B[1;32m     82\u001B[0m         force_all_finite\u001B[38;5;241m=\u001B[39mensure_all_finite,\n",
       "\u001B[1;32m     83\u001B[0m         ensure_min_samples\u001B[38;5;241m=\u001B[39mensure_min_samples,\n",
       "\u001B[1;32m     84\u001B[0m     )\n",
       "\u001B[1;32m     86\u001B[0m     \u001B[38;5;66;03m# this only needs to be updated at fit() time\u001B[39;00m\n",
       "\u001B[1;32m     87\u001B[0m     _estimator\u001B[38;5;241m.\u001B[39mn_features_in_ \u001B[38;5;241m=\u001B[39m n_features_in_\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/utils/validation.py:1147\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n",
       "\u001B[1;32m   1142\u001B[0m         estimator_name \u001B[38;5;241m=\u001B[39m _check_estimator_name(estimator)\n",
       "\u001B[1;32m   1143\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n",
       "\u001B[1;32m   1144\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires y to be passed, but the target y is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   1145\u001B[0m     )\n",
       "\u001B[0;32m-> 1147\u001B[0m X \u001B[38;5;241m=\u001B[39m check_array(\n",
       "\u001B[1;32m   1148\u001B[0m     X,\n",
       "\u001B[1;32m   1149\u001B[0m     accept_sparse\u001B[38;5;241m=\u001B[39maccept_sparse,\n",
       "\u001B[1;32m   1150\u001B[0m     accept_large_sparse\u001B[38;5;241m=\u001B[39maccept_large_sparse,\n",
       "\u001B[1;32m   1151\u001B[0m     dtype\u001B[38;5;241m=\u001B[39mdtype,\n",
       "\u001B[1;32m   1152\u001B[0m     order\u001B[38;5;241m=\u001B[39morder,\n",
       "\u001B[1;32m   1153\u001B[0m     copy\u001B[38;5;241m=\u001B[39mcopy,\n",
       "\u001B[1;32m   1154\u001B[0m     force_all_finite\u001B[38;5;241m=\u001B[39mforce_all_finite,\n",
       "\u001B[1;32m   1155\u001B[0m     ensure_2d\u001B[38;5;241m=\u001B[39mensure_2d,\n",
       "\u001B[1;32m   1156\u001B[0m     allow_nd\u001B[38;5;241m=\u001B[39mallow_nd,\n",
       "\u001B[1;32m   1157\u001B[0m     ensure_min_samples\u001B[38;5;241m=\u001B[39mensure_min_samples,\n",
       "\u001B[1;32m   1158\u001B[0m     ensure_min_features\u001B[38;5;241m=\u001B[39mensure_min_features,\n",
       "\u001B[1;32m   1159\u001B[0m     estimator\u001B[38;5;241m=\u001B[39mestimator,\n",
       "\u001B[1;32m   1160\u001B[0m     input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m   1161\u001B[0m )\n",
       "\u001B[1;32m   1163\u001B[0m y \u001B[38;5;241m=\u001B[39m _check_y(y, multi_output\u001B[38;5;241m=\u001B[39mmulti_output, y_numeric\u001B[38;5;241m=\u001B[39my_numeric, estimator\u001B[38;5;241m=\u001B[39mestimator)\n",
       "\u001B[1;32m   1165\u001B[0m check_consistent_length(X, y)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/utils/validation.py:978\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n",
       "\u001B[1;32m    976\u001B[0m     n_features \u001B[38;5;241m=\u001B[39m array\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]\n",
       "\u001B[1;32m    977\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_features \u001B[38;5;241m<\u001B[39m ensure_min_features:\n",
       "\u001B[0;32m--> 978\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n",
       "\u001B[1;32m    979\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m feature(s) (shape=\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m) while\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    980\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m a minimum of \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m is required\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    981\u001B[0m             \u001B[38;5;241m%\u001B[39m (n_features, array\u001B[38;5;241m.\u001B[39mshape, ensure_min_features, context)\n",
       "\u001B[1;32m    982\u001B[0m         )\n",
       "\u001B[1;32m    984\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copy:\n",
       "\u001B[1;32m    985\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_numpy_namespace(xp):\n",
       "\u001B[1;32m    986\u001B[0m         \u001B[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mValueError\u001B[0m: Found array with 0 feature(s) (shape=(24, 0)) while a minimum of 1 is required."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "ValueError",
        "evalue": "Found array with 0 feature(s) (shape=(24, 0)) while a minimum of 1 is required."
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>ValueError</span>: Found array with 0 feature(s) (shape=(24, 0)) while a minimum of 1 is required."
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
        "File \u001B[0;32m<command-5255411454592102>, line 79\u001B[0m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;66;03m# 10. Modelo final con variables seleccionadas\u001B[39;00m\n\u001B[1;32m     70\u001B[0m pipeline_final \u001B[38;5;241m=\u001B[39m Pipeline(steps\u001B[38;5;241m=\u001B[39m[\n\u001B[1;32m     71\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprep\u001B[39m\u001B[38;5;124m\"\u001B[39m, ColumnTransformer(\n\u001B[1;32m     72\u001B[0m         transformers\u001B[38;5;241m=\u001B[39m[\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     76\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m, LGBMRegressor(n_estimators\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m300\u001B[39m, learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.03\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)),\n\u001B[1;32m     77\u001B[0m ])\n\u001B[0;32m---> 79\u001B[0m pipeline_final\u001B[38;5;241m.\u001B[39mfit(X_train_red, y_train)\n\u001B[1;32m     80\u001B[0m predicciones \u001B[38;5;241m=\u001B[39m pipeline_final\u001B[38;5;241m.\u001B[39mpredict(X_test_red)\n\u001B[1;32m     82\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mR² en prueba:\u001B[39m\u001B[38;5;124m\"\u001B[39m, r2_score(y_test, predicciones)\u001B[38;5;241m.\u001B[39mround(\u001B[38;5;241m4\u001B[39m))\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:578\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    576\u001B[0m     patch_function\u001B[38;5;241m.\u001B[39mcall(call_original, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    577\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 578\u001B[0m     patch_function(call_original, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    580\u001B[0m session\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msucceeded\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    582\u001B[0m try_log_autologging_event(\n\u001B[1;32m    583\u001B[0m     AutologgingEventLogger\u001B[38;5;241m.\u001B[39mget_logger()\u001B[38;5;241m.\u001B[39mlog_patch_function_success,\n\u001B[1;32m    584\u001B[0m     session,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    588\u001B[0m     kwargs,\n\u001B[1;32m    589\u001B[0m )\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:251\u001B[0m, in \u001B[0;36mwith_managed_run.<locals>.patch_with_managed_run\u001B[0;34m(original, *args, **kwargs)\u001B[0m\n\u001B[1;32m    248\u001B[0m     managed_run \u001B[38;5;241m=\u001B[39m create_managed_run()\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 251\u001B[0m     result \u001B[38;5;241m=\u001B[39m patch_function(original, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mException\u001B[39;00m, \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m):\n\u001B[1;32m    253\u001B[0m     \u001B[38;5;66;03m# In addition to standard Python exceptions, handle keyboard interrupts to ensure\u001B[39;00m\n\u001B[1;32m    254\u001B[0m     \u001B[38;5;66;03m# that runs are terminated if a user prematurely interrupts training execution\u001B[39;00m\n\u001B[1;32m    255\u001B[0m     \u001B[38;5;66;03m# (e.g. via sigint / ctrl-c)\u001B[39;00m\n\u001B[1;32m    256\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m managed_run:\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/mlflow/sklearn/__init__.py:1652\u001B[0m, in \u001B[0;36m_autolog.<locals>.patched_fit\u001B[0;34m(fit_impl, allow_children_patch, original, self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1648\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mshould_log():\n\u001B[1;32m   1649\u001B[0m     \u001B[38;5;66;03m# In `fit_mlflow` call, it will also call metric API for computing training metrics\u001B[39;00m\n\u001B[1;32m   1650\u001B[0m     \u001B[38;5;66;03m# so we need temporarily disable the post_training_metrics patching.\u001B[39;00m\n\u001B[1;32m   1651\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m _AUTOLOGGING_METRICS_MANAGER\u001B[38;5;241m.\u001B[39mdisable_log_post_training_metrics():\n\u001B[0;32m-> 1652\u001B[0m         result \u001B[38;5;241m=\u001B[39m fit_impl(original, \u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1653\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m should_log_post_training_metrics:\n\u001B[1;32m   1654\u001B[0m         _AUTOLOGGING_METRICS_MANAGER\u001B[38;5;241m.\u001B[39mregister_model(\n\u001B[1;32m   1655\u001B[0m             \u001B[38;5;28mself\u001B[39m, mlflow\u001B[38;5;241m.\u001B[39mactive_run()\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mrun_id\n\u001B[1;32m   1656\u001B[0m         )\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/mlflow/sklearn/__init__.py:1427\u001B[0m, in \u001B[0;36m_autolog.<locals>.fit_mlflow\u001B[0;34m(original, self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1425\u001B[0m _log_pretraining_metadata(autologging_client, \u001B[38;5;28mself\u001B[39m, X, y_true)\n\u001B[1;32m   1426\u001B[0m params_logging_future \u001B[38;5;241m=\u001B[39m autologging_client\u001B[38;5;241m.\u001B[39mflush(synchronous\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m-> 1427\u001B[0m fit_output \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1428\u001B[0m _log_posttraining_metadata(autologging_client, \u001B[38;5;28mself\u001B[39m, X, y_true, sample_weight)\n\u001B[1;32m   1429\u001B[0m autologging_client\u001B[38;5;241m.\u001B[39mflush(synchronous\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:559\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001B[0;34m(*og_args, **og_kwargs)\u001B[0m\n\u001B[1;32m    556\u001B[0m         original_result \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;241m*\u001B[39m_og_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_og_kwargs)\n\u001B[1;32m    557\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n\u001B[0;32m--> 559\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:494\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001B[0;34m(original_fn, og_args, og_kwargs)\u001B[0m\n\u001B[1;32m    485\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    486\u001B[0m     try_log_autologging_event(\n\u001B[1;32m    487\u001B[0m         AutologgingEventLogger\u001B[38;5;241m.\u001B[39mget_logger()\u001B[38;5;241m.\u001B[39mlog_original_function_start,\n\u001B[1;32m    488\u001B[0m         session,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    492\u001B[0m         og_kwargs,\n\u001B[1;32m    493\u001B[0m     )\n\u001B[0;32m--> 494\u001B[0m     original_fn_result \u001B[38;5;241m=\u001B[39m original_fn(\u001B[38;5;241m*\u001B[39mog_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mog_kwargs)\n\u001B[1;32m    496\u001B[0m     try_log_autologging_event(\n\u001B[1;32m    497\u001B[0m         AutologgingEventLogger\u001B[38;5;241m.\u001B[39mget_logger()\u001B[38;5;241m.\u001B[39mlog_original_function_success,\n\u001B[1;32m    498\u001B[0m         session,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    502\u001B[0m         og_kwargs,\n\u001B[1;32m    503\u001B[0m     )\n\u001B[1;32m    504\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_fn_result\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:556\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001B[0;34m(*_og_args, **_og_kwargs)\u001B[0m\n\u001B[1;32m    548\u001B[0m \u001B[38;5;66;03m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001B[39;00m\n\u001B[1;32m    549\u001B[0m \u001B[38;5;66;03m# during original function execution, even if silent mode is enabled\u001B[39;00m\n\u001B[1;32m    550\u001B[0m \u001B[38;5;66;03m# (`silent=True`), since these warnings originate from the ML framework\u001B[39;00m\n\u001B[1;32m    551\u001B[0m \u001B[38;5;66;03m# or one of its dependencies and are likely relevant to the caller\u001B[39;00m\n\u001B[1;32m    552\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n\u001B[1;32m    553\u001B[0m     disable_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    554\u001B[0m     reroute_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    555\u001B[0m ):\n\u001B[0;32m--> 556\u001B[0m     original_result \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;241m*\u001B[39m_og_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_og_kwargs)\n\u001B[1;32m    557\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n",
        "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/MLWorkloadsInstrumentation/_sklearn.py:29\u001B[0m, in \u001B[0;36m_create_patch_function.<locals>.patch_function\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     28\u001B[0m     original_succeeded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m---> 29\u001B[0m     original_result \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     30\u001B[0m     original_succeeded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/base.py:1151\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1144\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1147\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1148\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1149\u001B[0m     )\n\u001B[1;32m   1150\u001B[0m ):\n\u001B[0;32m-> 1151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/pipeline.py:420\u001B[0m, in \u001B[0;36mPipeline.fit\u001B[0;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[1;32m    418\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_final_estimator \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpassthrough\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    419\u001B[0m         fit_params_last_step \u001B[38;5;241m=\u001B[39m fit_params_steps[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m][\u001B[38;5;241m0\u001B[39m]]\n\u001B[0;32m--> 420\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_final_estimator\u001B[38;5;241m.\u001B[39mfit(Xt, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params_last_step)\n\u001B[1;32m    422\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:458\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    444\u001B[0m     active_session_failed\n\u001B[1;32m    445\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m autologging_is_disabled(autologging_integration)\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    452\u001B[0m     \u001B[38;5;66;03m# warning behavior during original function execution, since autologging is being\u001B[39;00m\n\u001B[1;32m    453\u001B[0m     \u001B[38;5;66;03m# skipped\u001B[39;00m\n\u001B[1;32m    454\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n\u001B[1;32m    455\u001B[0m         disable_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    456\u001B[0m         reroute_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    457\u001B[0m     ):\n\u001B[0;32m--> 458\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m original(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    460\u001B[0m \u001B[38;5;66;03m# Whether or not the original / underlying function has been called during the\u001B[39;00m\n\u001B[1;32m    461\u001B[0m \u001B[38;5;66;03m# execution of patched code\u001B[39;00m\n\u001B[1;32m    462\u001B[0m original_has_been_called \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-049cd929-ff6b-45f7-85dc-aeefbfc6f73e/lib/python3.11/site-packages/lightgbm/sklearn.py:1398\u001B[0m, in \u001B[0;36mLGBMRegressor.fit\u001B[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001B[0m\n\u001B[1;32m   1381\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(  \u001B[38;5;66;03m# type: ignore[override]\u001B[39;00m\n\u001B[1;32m   1382\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1383\u001B[0m     X: _LGBM_ScikitMatrixLike,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1395\u001B[0m     init_model: Optional[Union[\u001B[38;5;28mstr\u001B[39m, Path, Booster, LGBMModel]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1396\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLGBMRegressor\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   1397\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1398\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mfit(\n\u001B[1;32m   1399\u001B[0m         X,\n\u001B[1;32m   1400\u001B[0m         y,\n\u001B[1;32m   1401\u001B[0m         sample_weight\u001B[38;5;241m=\u001B[39msample_weight,\n\u001B[1;32m   1402\u001B[0m         init_score\u001B[38;5;241m=\u001B[39minit_score,\n\u001B[1;32m   1403\u001B[0m         eval_set\u001B[38;5;241m=\u001B[39meval_set,\n\u001B[1;32m   1404\u001B[0m         eval_names\u001B[38;5;241m=\u001B[39meval_names,\n\u001B[1;32m   1405\u001B[0m         eval_sample_weight\u001B[38;5;241m=\u001B[39meval_sample_weight,\n\u001B[1;32m   1406\u001B[0m         eval_init_score\u001B[38;5;241m=\u001B[39meval_init_score,\n\u001B[1;32m   1407\u001B[0m         eval_metric\u001B[38;5;241m=\u001B[39meval_metric,\n\u001B[1;32m   1408\u001B[0m         feature_name\u001B[38;5;241m=\u001B[39mfeature_name,\n\u001B[1;32m   1409\u001B[0m         categorical_feature\u001B[38;5;241m=\u001B[39mcategorical_feature,\n\u001B[1;32m   1410\u001B[0m         callbacks\u001B[38;5;241m=\u001B[39mcallbacks,\n\u001B[1;32m   1411\u001B[0m         init_model\u001B[38;5;241m=\u001B[39minit_model,\n\u001B[1;32m   1412\u001B[0m     )\n\u001B[1;32m   1413\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:458\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    444\u001B[0m     active_session_failed\n\u001B[1;32m    445\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m autologging_is_disabled(autologging_integration)\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    452\u001B[0m     \u001B[38;5;66;03m# warning behavior during original function execution, since autologging is being\u001B[39;00m\n\u001B[1;32m    453\u001B[0m     \u001B[38;5;66;03m# skipped\u001B[39;00m\n\u001B[1;32m    454\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n\u001B[1;32m    455\u001B[0m         disable_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    456\u001B[0m         reroute_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    457\u001B[0m     ):\n\u001B[0;32m--> 458\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m original(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    460\u001B[0m \u001B[38;5;66;03m# Whether or not the original / underlying function has been called during the\u001B[39;00m\n\u001B[1;32m    461\u001B[0m \u001B[38;5;66;03m# execution of patched code\u001B[39;00m\n\u001B[1;32m    462\u001B[0m original_has_been_called \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-049cd929-ff6b-45f7-85dc-aeefbfc6f73e/lib/python3.11/site-packages/lightgbm/sklearn.py:949\u001B[0m, in \u001B[0;36mLGBMModel.fit\u001B[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001B[0m\n\u001B[1;32m    946\u001B[0m params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetric\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m [metric \u001B[38;5;28;01mfor\u001B[39;00m metric \u001B[38;5;129;01min\u001B[39;00m params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetric\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m metric \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m]\n\u001B[1;32m    948\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(X, (pd_DataFrame, dt_DataTable)):\n\u001B[0;32m--> 949\u001B[0m     _X, _y \u001B[38;5;241m=\u001B[39m _LGBMValidateData(\n\u001B[1;32m    950\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    951\u001B[0m         X,\n\u001B[1;32m    952\u001B[0m         y,\n\u001B[1;32m    953\u001B[0m         reset\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    954\u001B[0m         \u001B[38;5;66;03m# allow any input type (this validation is done further down, in lgb.Dataset())\u001B[39;00m\n\u001B[1;32m    955\u001B[0m         accept_sparse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    956\u001B[0m         \u001B[38;5;66;03m# do not raise an error if Inf of NaN values are found (LightGBM handles these internally)\u001B[39;00m\n\u001B[1;32m    957\u001B[0m         ensure_all_finite\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    958\u001B[0m         \u001B[38;5;66;03m# raise an error on 0-row and 1-row inputs\u001B[39;00m\n\u001B[1;32m    959\u001B[0m         ensure_min_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m    960\u001B[0m     )\n\u001B[1;32m    961\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    962\u001B[0m         sample_weight \u001B[38;5;241m=\u001B[39m _LGBMCheckSampleWeight(sample_weight, _X)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-049cd929-ff6b-45f7-85dc-aeefbfc6f73e/lib/python3.11/site-packages/lightgbm/compat.py:78\u001B[0m, in \u001B[0;36mvalidate_data\u001B[0;34m(_estimator, X, y, accept_sparse, ensure_all_finite, ensure_min_samples, **ignored_kwargs)\u001B[0m\n\u001B[1;32m     71\u001B[0m     X \u001B[38;5;241m=\u001B[39m check_array(\n\u001B[1;32m     72\u001B[0m         X,\n\u001B[1;32m     73\u001B[0m         accept_sparse\u001B[38;5;241m=\u001B[39maccept_sparse,\n\u001B[1;32m     74\u001B[0m         force_all_finite\u001B[38;5;241m=\u001B[39mensure_all_finite,\n\u001B[1;32m     75\u001B[0m         ensure_min_samples\u001B[38;5;241m=\u001B[39mensure_min_samples,\n\u001B[1;32m     76\u001B[0m     )\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 78\u001B[0m     X, y \u001B[38;5;241m=\u001B[39m check_X_y(\n\u001B[1;32m     79\u001B[0m         X,\n\u001B[1;32m     80\u001B[0m         y,\n\u001B[1;32m     81\u001B[0m         accept_sparse\u001B[38;5;241m=\u001B[39maccept_sparse,\n\u001B[1;32m     82\u001B[0m         force_all_finite\u001B[38;5;241m=\u001B[39mensure_all_finite,\n\u001B[1;32m     83\u001B[0m         ensure_min_samples\u001B[38;5;241m=\u001B[39mensure_min_samples,\n\u001B[1;32m     84\u001B[0m     )\n\u001B[1;32m     86\u001B[0m     \u001B[38;5;66;03m# this only needs to be updated at fit() time\u001B[39;00m\n\u001B[1;32m     87\u001B[0m     _estimator\u001B[38;5;241m.\u001B[39mn_features_in_ \u001B[38;5;241m=\u001B[39m n_features_in_\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/utils/validation.py:1147\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[1;32m   1142\u001B[0m         estimator_name \u001B[38;5;241m=\u001B[39m _check_estimator_name(estimator)\n\u001B[1;32m   1143\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1144\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires y to be passed, but the target y is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1145\u001B[0m     )\n\u001B[0;32m-> 1147\u001B[0m X \u001B[38;5;241m=\u001B[39m check_array(\n\u001B[1;32m   1148\u001B[0m     X,\n\u001B[1;32m   1149\u001B[0m     accept_sparse\u001B[38;5;241m=\u001B[39maccept_sparse,\n\u001B[1;32m   1150\u001B[0m     accept_large_sparse\u001B[38;5;241m=\u001B[39maccept_large_sparse,\n\u001B[1;32m   1151\u001B[0m     dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[1;32m   1152\u001B[0m     order\u001B[38;5;241m=\u001B[39morder,\n\u001B[1;32m   1153\u001B[0m     copy\u001B[38;5;241m=\u001B[39mcopy,\n\u001B[1;32m   1154\u001B[0m     force_all_finite\u001B[38;5;241m=\u001B[39mforce_all_finite,\n\u001B[1;32m   1155\u001B[0m     ensure_2d\u001B[38;5;241m=\u001B[39mensure_2d,\n\u001B[1;32m   1156\u001B[0m     allow_nd\u001B[38;5;241m=\u001B[39mallow_nd,\n\u001B[1;32m   1157\u001B[0m     ensure_min_samples\u001B[38;5;241m=\u001B[39mensure_min_samples,\n\u001B[1;32m   1158\u001B[0m     ensure_min_features\u001B[38;5;241m=\u001B[39mensure_min_features,\n\u001B[1;32m   1159\u001B[0m     estimator\u001B[38;5;241m=\u001B[39mestimator,\n\u001B[1;32m   1160\u001B[0m     input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1161\u001B[0m )\n\u001B[1;32m   1163\u001B[0m y \u001B[38;5;241m=\u001B[39m _check_y(y, multi_output\u001B[38;5;241m=\u001B[39mmulti_output, y_numeric\u001B[38;5;241m=\u001B[39my_numeric, estimator\u001B[38;5;241m=\u001B[39mestimator)\n\u001B[1;32m   1165\u001B[0m check_consistent_length(X, y)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/utils/validation.py:978\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m    976\u001B[0m     n_features \u001B[38;5;241m=\u001B[39m array\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m    977\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_features \u001B[38;5;241m<\u001B[39m ensure_min_features:\n\u001B[0;32m--> 978\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    979\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m feature(s) (shape=\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m) while\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    980\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m a minimum of \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m is required\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    981\u001B[0m             \u001B[38;5;241m%\u001B[39m (n_features, array\u001B[38;5;241m.\u001B[39mshape, ensure_min_features, context)\n\u001B[1;32m    982\u001B[0m         )\n\u001B[1;32m    984\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copy:\n\u001B[1;32m    985\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_numpy_namespace(xp):\n\u001B[1;32m    986\u001B[0m         \u001B[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001B[39;00m\n",
        "\u001B[0;31mValueError\u001B[0m: Found array with 0 feature(s) (shape=(24, 0)) while a minimum of 1 is required."
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0. Importaciones necesarias\n",
    "from Lector_deConsulta import ConsultaDB\n",
    "import pandas as pd\n",
    "import shap\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# 1. Instanciar la clase\n",
    "lector = ConsultaDB()\n",
    "\n",
    "# 2. Obtener los datos\n",
    "df = lector.ejecutar_consulta()\n",
    "\n",
    "# O un archivo plano:\n",
    "# df = lector.cargar_archivo(\"/dbfs/FileStore/datos/mi_archivo.csv\")\n",
    "\n",
    "# 3. Limpieza inicial\n",
    "df = df.drop_duplicates()\n",
    "df = df.loc[:, ~(df.isna().all() | (df.nunique() == 1))]\n",
    "\n",
    "# 4. Separar en variables explicativas y objetivo\n",
    "objetivo = \"Dinero\"\n",
    "X = df.drop(columns=[objetivo])\n",
    "y = df[objetivo]\n",
    "\n",
    "# 5. Separar entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 6. Preprocesamiento: separar numéricas y categóricas\n",
    "num_cols = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "cat_cols = [col for col in X.columns if col not in num_cols]\n",
    "\n",
    "preprocesador = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", \"passthrough\", num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "    ]\n",
    ")\n",
    "#supongo que el dataFrame es grande (va a dar error dado que el nuestro es pequeño)\n",
    "modelo_base = LGBMRegressor(n_estimators=300, learning_rate=0.05, random_state=42)\n",
    "pipeline = Pipeline(steps=[(\"prep\", preprocesador), (\"model\", modelo_base)])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 7. Importancia de variables con SHAP\n",
    "explainer = shap.Explainer(pipeline[\"model\"])\n",
    "valores_shap = explainer(pipeline[\"prep\"].transform(X_train))\n",
    "\n",
    "importancia = pd.DataFrame({\n",
    "    \"variable\": X_train.columns,\n",
    "    \"importancia\": valores_shap.abs.mean(0).values\n",
    "}).sort_values(\"importancia\", ascending=False)\n",
    "\n",
    "display(importancia)\n",
    "\n",
    "# 8. Selección automática de variables (hasta cubrir 95 % de importancia)\n",
    "cumsum = importancia[\"importancia\"].cumsum() / importancia[\"importancia\"].sum()\n",
    "seleccionadas = importancia.loc[cumsum <= 0.95, \"variable\"].tolist()\n",
    "\n",
    "print(f\"Variables seleccionadas ({len(seleccionadas)}):\", seleccionadas)\n",
    "\n",
    "# 9. Crear subconjuntos reducidos\n",
    "X_train_red = X_train[seleccionadas]\n",
    "X_test_red = X_test[seleccionadas]\n",
    "\n",
    "# 10. Modelo final con variables seleccionadas\n",
    "pipeline_final = Pipeline(steps=[\n",
    "    (\"prep\", ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", \"passthrough\", [c for c in seleccionadas if c in num_cols]),\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), [c for c in seleccionadas if c in cat_cols]),\n",
    "        ])),\n",
    "    (\"model\", LGBMRegressor(n_estimators=300, learning_rate=0.03, random_state=42)),\n",
    "])\n",
    "\n",
    "pipeline_final.fit(X_train_red, y_train)\n",
    "predicciones = pipeline_final.predict(X_test_red)\n",
    "\n",
    "print(\"R² en prueba:\", r2_score(y_test, predicciones).round(4))\n",
    "\n",
    "# 11. Exportar resultados\n",
    "lector.exportar(df, nombre_archivo=\"datos_completos\", formato=\"parquet\")\n",
    "lector.exportar(importancia, nombre_archivo=\"importancia_variables\", formato=\"csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8567acd6-1c5a-44ad-af6b-4d8360b75dfa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# INSTALAMOS LAS LIBRERIAS NECESARIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd03dcc4-ce81-4850-a4e1-7f87bc81d357",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==2.2.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-049cd929-ff6b-45f7-85dc-aeefbfc6f73e/lib/python3.11/site-packages (from -r /Workspace/Users/azzure_roma_29@hotmail.com/ENTREGAS/requirements.txt (line 1)) (2.2.3)\nRequirement already satisfied: SQLAlchemy==2.0.40 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-049cd929-ff6b-45f7-85dc-aeefbfc6f73e/lib/python3.11/site-packages (from -r /Workspace/Users/azzure_roma_29@hotmail.com/ENTREGAS/requirements.txt (line 2)) (2.0.40)\nRequirement already satisfied: mysql-connector-python==9.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-049cd929-ff6b-45f7-85dc-aeefbfc6f73e/lib/python3.11/site-packages (from -r /Workspace/Users/azzure_roma_29@hotmail.com/ENTREGAS/requirements.txt (line 3)) (9.3.0)\nRequirement already satisfied: pyarrow==20.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-049cd929-ff6b-45f7-85dc-aeefbfc6f73e/lib/python3.11/site-packages (from -r /Workspace/Users/azzure_roma_29@hotmail.com/ENTREGAS/requirements.txt (line 4)) (20.0.0)\nRequirement already satisfied: openpyxl==3.1.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-049cd929-ff6b-45f7-85dc-aeefbfc6f73e/lib/python3.11/site-packages (from -r /Workspace/Users/azzure_roma_29@hotmail.com/ENTREGAS/requirements.txt (line 5)) (3.1.5)\nCollecting lightgbm (from -r /Workspace/Users/azzure_roma_29@hotmail.com/ENTREGAS/requirements.txt (line 6))\n  Obtaining dependency information for lightgbm from https://files.pythonhosted.org/packages/42/86/dabda8fbcb1b00bcfb0003c3776e8ade1aa7b413dff0a2c08f457dace22f/lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl.metadata\n  Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\nCollecting shap (from -r /Workspace/Users/azzure_roma_29@hotmail.com/ENTREGAS/requirements.txt (line 7))\n  Obtaining dependency information for shap from https://files.pythonhosted.org/packages/c8/ae/4a16ad24420966a6e3b71aa359756ab3314da38a0bc7e5ca83058814c9a9/shap-0.47.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading shap-0.47.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\nRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.11/site-packages (from -r /Workspace/Users/azzure_roma_29@hotmail.com/ENTREGAS/requirements.txt (line 8)) (1.3.0)\nRequirement already satisfied: numpy>=1.23.2 in /databricks/python3/lib/python3.11/site-packages (from pandas==2.2.3->-r /Workspace/Users/azzure_roma_29@hotmail.com/ENTREGAS/requirements.txt (line 1)) (1.23.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /databricks/python3/lib/python3.11/site-packages (from pandas==2.2.3->-r /Workspace/Users/azzure_roma_29@hotmail.com/ENTREGAS/requirements.txt (line 1)) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.11/site-packages (from pandas==2.2.3->-r /Workspace/Users/azzure_roma_29@hotmail.com/ENTREGAS/requirements.txt (line 1)) (2022.7)\nRequirement already satisfied: tzdata>=2022.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-049cd929-ff6b-45f7-85dc-aeefbfc6f73e/lib/python3.11/site-packages (from pandas==2.2.3->-r /Workspace/Users/azzure_roma_29@hotmail.com/ENTREGAS/requirements.txt (line 1)) (2025.2)\nRequirement already satisfied: greenlet>=1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-049cd929-ff6b-45f7-85dc-aeefbfc6f73e/lib/python3.11/site-packages (from SQLAlchemy==2.0.40->-r /Workspace/Users/azzure_roma_29@hotmail.com/ENTREGAS/requirements.txt (line 2)) (3.2.2)\nRequirement already satisfied: typing-extensions>=4.6.0 in /databricks/python3/lib/python3.11/site-packages (from SQLAlchemy==2.0.40->-r /Workspace/Users/azzure_roma_29@hotmail.com/ENTREGAS/requirements.txt (line 2)) (4.10.0)\nRequirement already satisfied: et-xmlfile in /local_disk0/.ephemeral_nfs/envs/pythonEnv-049cd929-ff6b-45f7-85dc-aeefbfc6f73e/lib/python3.11/site-packages (from openpyxl==3.1.5->-r /Workspace/Users/azzure_roma_29@hotmail.com/ENTREGAS/requirements.txt (line 5)) (2.0.0)\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.11/site-packages (from lightgbm->-r /Workspace/Users/azzure_roma_29@hotmail.com/ENTREGAS/requirements.txt (line 6)) (1.11.1)\nCollecting tqdm>=4.27.0 (from shap->-r /Workspace/Users/azzure_roma_29@hotmail.com/ENTREGAS/requirements.txt (line 7))\n  Obtaining dependency information for tqdm>=4.27.0 from https://files.pythonhosted.org/packages/d0/30/dc54f88dd4a2b5dc8a0279bdd7270e735851848b762aeb1c1184ed1f6b14/tqdm-4.67.1-py3-none-any.whl.metadata\n  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/57.7 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m57.7/57.7 kB\u001B[0m \u001B[31m5.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: packaging>20.9 in /databricks/python3/lib/python3.11/site-packages (from shap->-r /Workspace/Users/azzure_roma_29@hotmail.com/ENTREGAS/requirements.txt (line 7)) (23.2)\nCollecting slicer==0.0.8 (from shap->-r /Workspace/Users/azzure_roma_29@hotmail.com/ENTREGAS/requirements.txt (line 7))\n  Obtaining dependency information for slicer==0.0.8 from https://files.pythonhosted.org/packages/63/81/9ef641ff4e12cbcca30e54e72fb0951a2ba195d0cda0ba4100e532d929db/slicer-0.0.8-py3-none-any.whl.metadata\n  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\nCollecting numba>=0.54 (from shap->-r /Workspace/Users/azzure_roma_29@hotmail.com/ENTREGAS/requirements.txt (line 7))\n  Obtaining dependency information for numba>=0.54 from https://files.pythonhosted.org/packages/97/c8/8740616c8436c86c1b9a62e72cb891177d2c34c2d24ddcde4c390371bf4c/numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n  Downloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\nRequirement already satisfied: cloudpickle in /databricks/python3/lib/python3.11/site-packages (from shap->-r /Workspace/Users/azzure_roma_29@hotmail.com/ENTREGAS/requirements.txt (line 7)) (2.2.1)\nRequirement already satisfied: joblib>=1.1.1 in /databricks/python3/lib/python3.11/site-packages (from scikit-learn->-r /Workspace/Users/azzure_roma_29@hotmail.com/ENTREGAS/requirements.txt (line 8)) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.11/site-packages (from scikit-learn->-r /Workspace/Users/azzure_roma_29@hotmail.com/ENTREGAS/requirements.txt (line 8)) (2.2.0)\nCollecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.54->shap->-r /Workspace/Users/azzure_roma_29@hotmail.com/ENTREGAS/requirements.txt (line 7))\n  Obtaining dependency information for llvmlite<0.45,>=0.44.0dev0 from https://files.pythonhosted.org/packages/99/fe/d030f1849ebb1f394bb3f7adad5e729b634fb100515594aca25c354ffc62/llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\nCollecting numpy>=1.23.2 (from pandas==2.2.3->-r /Workspace/Users/azzure_roma_29@hotmail.com/ENTREGAS/requirements.txt (line 1))\n  Obtaining dependency information for numpy>=1.23.2 from https://files.pythonhosted.org/packages/ad/c9/1bf6ada582eebcbe8978f5feb26584cd2b39f94ededeea034ca8f84af8c8/numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/62.0 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m62.0/62.0 kB\u001B[0m \u001B[31m8.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.3->-r /Workspace/Users/azzure_roma_29@hotmail.com/ENTREGAS/requirements.txt (line 1)) (1.16.0)\n  Obtaining dependency information for numpy>=1.23.2 from https://files.pythonhosted.org/packages/3a/d0/edc009c27b406c4f9cbc79274d6e46d634d139075492ad055e3d68445925/numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/61.0 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m61.0/61.0 kB\u001B[0m \u001B[31m4.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/3.6 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.8/3.6 MB\u001B[0m \u001B[31m24.1 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.2/3.6 MB\u001B[0m \u001B[31m32.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m3.6/3.6 MB\u001B[0m \u001B[31m39.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.6/3.6 MB\u001B[0m \u001B[31m31.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading shap-0.47.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/1.0 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.0/1.0 MB\u001B[0m \u001B[31m52.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading slicer-0.0.8-py3-none-any.whl (15 kB)\nDownloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/3.8 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m3.8/3.8 MB\u001B[0m \u001B[31m115.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.8/3.8 MB\u001B[0m \u001B[31m62.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/18.3 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.5/18.3 MB\u001B[0m \u001B[31m224.8 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━\u001B[0m \u001B[32m17.7/18.3 MB\u001B[0m \u001B[31m286.9 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m290.8 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m290.8 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m290.8 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m290.8 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m290.8 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m290.8 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m290.8 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m290.8 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m290.8 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m290.8 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m290.8 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m18.3/18.3 MB\u001B[0m \u001B[31m23.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/78.5 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m78.5/78.5 kB\u001B[0m \u001B[31m14.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/42.4 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m10.2/42.4 MB\u001B[0m \u001B[31m306.0 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m20.1/42.4 MB\u001B[0m \u001B[31m286.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m25.3/42.4 MB\u001B[0m \u001B[31m196.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━\u001B[0m \u001B[32m31.1/42.4 MB\u001B[0m \u001B[31m164.2 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━\u001B[0m \u001B[32m39.2/42.4 MB\u001B[0m \u001B[31m217.3 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m42.4/42.4 MB\u001B[0m \u001B[31m233.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m42.4/42.4 MB\u001B[0m \u001B[31m233.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m42.4/42.4 MB\u001B[0m \u001B[31m233.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m42.4/42.4 MB\u001B[0m \u001B[31m233.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m42.4/42.4 MB\u001B[0m \u001B[31m233.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m42.4/42.4 MB\u001B[0m \u001B[31m233.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m42.4/42.4 MB\u001B[0m \u001B[31m38.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hInstalling collected packages: tqdm, slicer, numpy, llvmlite, numba, lightgbm, shap\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.23.5\n    Not uninstalling numpy at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-049cd929-ff6b-45f7-85dc-aeefbfc6f73e\n    Can't uninstall 'numpy'. No files were found to uninstall.\nSuccessfully installed lightgbm-4.6.0 llvmlite-0.44.0 numba-0.61.2 numpy-1.26.4 shap-0.47.2 slicer-0.0.8 tqdm-4.67.1\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -r \"/Workspace/Users/azzure_roma_29@hotmail.com/ENTREGAS/requirements.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "694b80b3-392e-4ce8-a1da-2087e01d2d78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Principal",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "python_trabajo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}